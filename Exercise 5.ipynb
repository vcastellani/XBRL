{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34031ad9",
   "metadata": {},
   "source": [
    "# Excercise 5: Financial Statement Analysis - Exchanges\n",
    "This exercise will focus on using Python and XBRL in creative ways. Using the SEC's Company JSON, we will match publicly traded tickers to their CIK and Exchange. This excercise will enable you to accelerate the process of creating datasets using public company tickers. \n",
    "\n",
    "For this exercise, letâ€™s explore financial differences between companies listed on the NYSE and Nasdaq by analyzing their intangible assets. We will use a JSON file containing company tickers, CIKs, and exchanges, and then filter the dataset to isolate NYSE and Nasdaq firms. After converting this information into a clean DataFrame, we will match it with XBRL data and calculate intangible assets (excluding goodwill) as a percentage of total assets. This allows us to assess whether tech-heavy Nasdaq firms tend to report higher proportions of intangible assets compared to more traditional NYSE firms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e7b0e",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Stata Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, json, requests, getpass, urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230e67c",
   "metadata": {},
   "source": [
    "## Step 2: Obtain XBRL API Access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass(prompt = 'Enter Your XBRL US Password: ')\n",
    "\n",
    "body_auth = {'username' : 'vac35@psu.edu', \n",
    "            'client_id': 'Obtain Client ID from XBRL Website', \n",
    "            'client_secret' : 'Obtain Client Secret from XBRL Website', \n",
    "            'password' : ''.join(password), \n",
    "            'grant_type' : 'password', \n",
    "            'platform' : 'ipynb' }\n",
    "\n",
    "payload = urlencode(body_auth)\n",
    "url = 'https://api.xbrl.us/oauth2/token'\n",
    "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "\n",
    "res = requests.request(\"POST\", url, data = payload, headers = headers)\n",
    "auth_json = res.json()\n",
    "\n",
    "if 'error' in auth_json:\n",
    "    print (\"Access Denied\")\n",
    "else:\n",
    "    print (\"Access Granted.\")\n",
    "    \n",
    "access_token = auth_json['access_token']\n",
    "refresh_token = auth_json['refresh_token']\n",
    "newaccess = ''\n",
    "newrefresh = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f10ac",
   "metadata": {},
   "source": [
    "## Step 3: Find CIKs Based off of Tickers\n",
    "This step is intended to show one of the ways you can quickly find a set of companies CIKs based upon their publicly traded Ticker. Using tickers is an easier way to find the company CIKs due to the difference between a companies brand name and the name that is legally filed with the SEC. \n",
    "\n",
    "The SEC provides a JSON file which contains each public companies CIK, Company Name, Ticker, and the Exchange it is traded on. https://www.sec.gov/file/company-tickers. You can download this link and follow the steps below to match a set of tickers for analysis. \n",
    "\n",
    "\n",
    "For this exercise I used ChatGPT to tell me the top 50 companies in market capitilization from the the two largest exchanges (New York Stock Exchange (NYSE) and Nasdaq). From there I asked for the tickers which are displayed below. This exercise will compare these companies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa60696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 NYSE\n",
    "[\"BRK.B\", \"V\", \"JPM\", \"JNJ\", \"WMT\", \"PG\", \"UNH\", \"XOM\", \"CVX\", \"HD\",\n",
    "    \"BAC\", \"KO\", \"ABBV\", \"MRK\", \"PEP\", \"MCD\", \"ABT\", \"GE\", \"IBM\", \"PM\",\n",
    "    \"VZ\", \"T\", \"LIN\", \"GS\", \"MS\", \"C\", \"CAT\", \"HON\", \"LMT\", \"RTX\", \"BA\",\n",
    "    \"F\", \"GM\", \"AXP\", \"TRV\", \"MO\", \"NEE\", \"DUK\", \"SO\", \"D\", \"EXC\",\n",
    "    \"AEP\", \"COP\", \"PSX\", \"VLO\", \"MPC\", \"OXY\", \"SCHW\", \"DIS\", \"CMCSA\", \"PFE\"\n",
    "]\n",
    "# 50 NASDAQ\n",
    "[ \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"GOOG\", \"AMZN\", \"META\", \"TSLA\", \"AVGO\", \"COST\",\n",
    "    \"NFLX\", \"PEP\", \"ADBE\", \"INTC\", \"CSCO\", \"AMD\", \"QCOM\", \"INTU\", \"TXN\", \"AMGN\",\n",
    "    \"PYPL\", \"BKNG\", \"CHTR\", \"GILD\", \"LRCX\", \"MRVL\", \"MU\", \"ADI\", \"ASML\", \"PANW\",\n",
    "    \"MNST\", \"REGN\", \"VRTX\", \"KLAC\", \"SNPS\", \"CDNS\", \"ILMN\", \"BIIB\", \"SGEN\", \"MRNA\",\n",
    "    \"ZM\", \"DOCU\", \"TEAM\", \"ZS\", \"WDAY\", \"DDOG\", \"SNOW\", \"CRWD\", \"OKTA\", \"ROKU\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6b224",
   "metadata": {},
   "source": [
    "#### Substep 3.1 Mapping Tickers\n",
    "\n",
    "Mapping the SEC's Company Tickers Exchange JSON. \n",
    "Using this link: https://www.sec.gov/file/company-tickers you can download the file. Once downloaded you can use your own file path to upload the JSON.\n",
    "\n",
    "This code loads a JSON file from the SEC that contains ticker symbols, company identifiers (CIKs), and exchange listings. It creates a mapping of each ticker to its corresponding CIK and exchange, then converts that mapping into a clean Pandas DataFrame. The final step filters the dataset to include only companies listed on the NYSE or Nasdaq exchanges\n",
    "\n",
    "*the JSON file will continue to update as companies become publicly traded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file containing company tickers, CIKs, and exchanges\n",
    "with open(\"C:/Users/andre/Downloads/company_tickers_exchange.json\", \"r\") as file: #Fill in the path to your file\n",
    "    company_data = json.load(file)\n",
    "\n",
    "# Access the 'data' key to retrieve the list of entries\n",
    "entries = company_data[\"data\"]\n",
    "\n",
    "# Create a mapping of ticker to CIK and exchange \n",
    "ticker_to_cik_exchange = {entry[2]: (entry[0], entry[3]) for entry in entries}  # 'ticker' is at index 2, 'cik' at index 0, and 'exchange' at index 3\n",
    "\n",
    "# Create a DataFrame from the mapping\n",
    "ticker_df = pd.DataFrame.from_dict(ticker_to_cik_exchange, orient='index', columns=['CIK', 'Exchange'])\n",
    "ticker_df.reset_index(inplace=True)\n",
    "ticker_df.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# Filter the DataFrame to include only tickers from the NYSE and NASDAQ exchanges\n",
    "Exchanges = ticker_df[ticker_df['Exchange'].isin(['NYSE','Nasdaq'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992de41d",
   "metadata": {},
   "source": [
    "Open the `Exchanges` DataFrame to ensure that the code was properly executed and the data is correctly filtered for NYSE and Nasdaq companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c47587",
   "metadata": {},
   "source": [
    "#### Substep 3.2 Matching Tickers\n",
    "Now we will insert the tickers we want to analyze into a list. Then we will use the `.isin()` function to match the tickers to their CIKs. This involves creating a list of tickers and filtering the `Exchanges` DataFrame to include only the rows where the 'Ticker' column matches one of the tickers in the list. The resulting DataFrame, `matched_tickers`, will contain only the relevant tickers along with their corresponding CIKs and exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tickers to match\n",
    "tickers_to_match = [\"BRK.B\", \"V\", \"JPM\", \"JNJ\", \"WMT\", \"PG\", \"UNH\", \"XOM\", \"CVX\", \"HD\", \"BAC\", \"KO\", \"ABBV\", \"MRK\", \"PEP\", \"MCD\", \"ABT\", \"GE\", \"IBM\", \"PM\", \"VZ\", \"T\", \"LIN\", \"GS\", \"MS\", \"C\", \"CAT\", \"HON\", \"LMT\", \"RTX\", \"BA\", \"F\", \"GM\", \"AXP\", \"TRV\", \"MO\", \"NEE\", \"DUK\", \"SO\", \"D\", \"EXC\", \"AEP\", \"COP\", \"PSX\", \"VLO\", \"MPC\", \"OXY\", \"SCHW\", \"DIS\", \"CMCSA\", \"PFE\", \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"GOOG\", \"AMZN\", \"META\", \"TSLA\", \"AVGO\", \"COST\", \"NFLX\", \"PEP\", \"ADBE\", \"INTC\", \"CSCO\", \"AMD\", \"QCOM\", \"INTU\", \"TXN\", \"AMGN\", \"PYPL\", \"BKNG\", \"CHTR\", \"GILD\", \"LRCX\", \"MRVL\", \"MU\", \"ADI\", \"ASML\", \"PANW\", \"MNST\", \"REGN\", \"VRTX\", \"KLAC\", \"SNPS\", \"CDNS\", \"ILMN\", \"BIIB\", \"SGEN\", \"MRNA\", \"ZM\", \"DOCU\", \"TEAM\", \"ZS\", \"WDAY\", \"DDOG\", \"SNOW\", \"CRWD\", \"OKTA\", \"ROKU\"]\n",
    "\n",
    "# Filter the Exchanges DataFrame to include only the tickers in the list\n",
    "matched_tickers = Exchanges[Exchanges['Ticker'].isin(tickers_to_match)]\n",
    "\n",
    "# Display the matched DataFrame\n",
    "matched_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff17c0",
   "metadata": {},
   "source": [
    "#### Substep 3.3 Formatting CIKs for Query\n",
    "\n",
    "In the SEC JSON file, CIKs (Central Index Keys) are not padded with leading zeros, which is required for consistency and proper querying. For example, a CIK like `3245678` should be formatted as `0003245678`. \n",
    "\n",
    "The first line of code ensures that all CIKs are padded with leading zeros to make them 10 digits long. This is achieved using the `zfill(10)` method, which adds zeros to the left of the string until it reaches the desired length.\n",
    "\n",
    "The second line of code converts the formatted CIKs into a list. This list will be used in subsequent steps to query the XBRL API and retrieve the relevant financial data for the companies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec06a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add three leading zeros to the CIK column\n",
    "matched_tickers['CIK'] = matched_tickers['CIK'].apply(lambda x: str(x).zfill(10))\n",
    "# Create a list of CIKs\n",
    "ciks = matched_tickers['CIK'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c565e",
   "metadata": {},
   "source": [
    "## Step 4: Query the XBRL API\n",
    "In this step, you need to identify the tags associated with your request. For this example, Intangible Assets and Assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "XBRL_Elements = ['IntangibleAssetsNetExcludingGoodwill','Assets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1ef16",
   "metadata": {},
   "source": [
    "#### Substep 4.1 Identify Other Relevant Parameters\n",
    "In this example we will focus on two years to use for a simple comparison from year to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filings = ['10-K']\n",
    "Years = ['2023','2024']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd92b66",
   "metadata": {},
   "source": [
    "#### Substep 4.2 Run Query\n",
    "The query will store the data in a DataFrame titled df. This step will look different from past exercises in the guide. Prior to converting API data pull into a DataFrame, the code will organize the concept tags (e.g., Assets) into their own column with their respective values. This will reduce the steps in cleaning the data and potential errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fields = ['entity.cik',\n",
    "          'entity.name.sort(ASC)',\n",
    "          'report.filing-date',\n",
    "          'period.fiscal-year',\n",
    "          'report.document-type',\n",
    "          'concept.local-name',\n",
    "          'fact.value',\n",
    "          'unit',\n",
    "          'report.sic-code']\n",
    "\n",
    "Parameters = {'concept.local-name': ','.join(XBRL_Elements),\n",
    "              'period.fiscal-year': ','.join(Years),\n",
    "              'unit': 'USD',\n",
    "              'report.document-type': ','.join(Filings),\n",
    "              'entity.cik': ','.join(ciks)} \n",
    "\n",
    "has_dimensions = 'FALSE'\n",
    "\n",
    "if has_dimensions == 'ALL':\n",
    "    dimension_options = ['TRUE', 'FALSE']\n",
    "else:\n",
    "    dimension_options = [has_dimensions]\n",
    "\n",
    "search_endpoint = 'https://api.xbrl.us/api/v1/fact/search'\n",
    "    \n",
    "all_res_list = []\n",
    "for dimensions_param in dimension_options:\n",
    "\n",
    "    print('Getting the data for: \"fact.has-dimensions\" = {}'.format(dimensions_param))\n",
    "    \n",
    "    done_retrieving_all_results = False\n",
    "    offset = 0\n",
    "\n",
    "    while not done_retrieving_all_results:\n",
    "\n",
    "        Parameters['fact.has-dimensions'] = dimensions_param\n",
    "        Parameters['fields'] = ','.join(Fields) + ',fact.offset({})'.format(offset) \n",
    "\n",
    "        res = requests.get(search_endpoint, params = Parameters, headers={'Authorization' : 'Bearer {}'.format(access_token)})\n",
    "        \n",
    "        res_json = res.json()\n",
    "        res_list = res_json['data']\n",
    "        all_res_list += res_list\n",
    "        \n",
    "        paging_dict = res_json['paging']\n",
    "\n",
    "        print('Number of Observations Obtained: ', paging_dict['count'])\n",
    "\n",
    "        if paging_dict['count'] >= 2000:\n",
    "            offset += paging_dict['count']\n",
    "        else:\n",
    "            done_retrieving_all_results = True\n",
    "\n",
    "\n",
    "\n",
    "restructured_data = []\n",
    "for item in all_res_list:\n",
    "    existing_entry = next(\n",
    "        (entry for entry in restructured_data if entry['entity.cik'] == item['entity.cik'] and entry['report.filing-date'] == item['report.filing-date']),\n",
    "        None\n",
    "    )\n",
    "   \n",
    "    if existing_entry:\n",
    "        existing_entry[item['concept.local-name']] = item['fact.value']\n",
    "    else:\n",
    "        new_entry = {\n",
    "            'entity.cik': item['entity.cik'],\n",
    "            'entity.name': item['entity.name'],\n",
    "            'report.filing-date': item['report.filing-date'],\n",
    "            'period.fiscal-year': item['period.fiscal-year'],\n",
    "            'report.document-type': item['report.document-type'],\n",
    "            'unit': item['unit'],\n",
    "            'report.sic-code': item['report.sic-code']\n",
    "        }\n",
    "        new_entry[item['concept.local-name']] = item['fact.value']\n",
    "        restructured_data.append(new_entry)\n",
    "    \n",
    "df = pd.DataFrame(restructured_data)\n",
    "print('Number of Observations: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600e5b4",
   "metadata": {},
   "source": [
    "# Step 5: Clean Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc54f2",
   "metadata": {},
   "source": [
    "#### Substep 5.1 Rename Columns\n",
    "In this step we will be changing the column names to be more presentable. There are different ways to do this using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f28a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(columns={'entity.cik': 'CIK',\n",
    "                   'entity.name': 'Company Name',\n",
    "                   'report.filing-date': 'Filing Date',\n",
    "                   'period.fiscal-year': 'Fiscal Year',\n",
    "                   'report.document-type': 'Document Type',\n",
    "                   'unit': 'Unit',\n",
    "                   'report.sic-code': 'SIC Code',\n",
    "                   'IntangibleAssetsNetExcludingGoodwill': 'IA'},\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218cfec6",
   "metadata": {},
   "source": [
    "#### Substep 5.2 Sort Data\n",
    "This code sorts the DataFrame df by the columns CIK, Company Name, and Fiscal Year in ascending order to organize the data in a logical sequence. After sorting, it resets the index of the DataFrame to ensure it starts from 0 and is sequential, dropping the old index to maintain a clean structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values CIK, company name, and fiscal year\n",
    "df.sort_values(by=['CIK', 'Company Name', 'Fiscal Year'], inplace=True)\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f7b88",
   "metadata": {},
   "source": [
    "#### Substep 5.3 Further Clean\n",
    "Drop potential CIK duplicates and drop rows that do not have Intangiable Assets or Asset data associated with the tags we used or our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['CIK','Company Name', 'Fiscal Year'], inplace=True)\n",
    "df.dropna(subset=['IA','Assets'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aef5bb",
   "metadata": {},
   "source": [
    "#### Substep 5.4 Merge \n",
    "\n",
    "Match the CIKs in the DataFrame with their corresponding tickers and exchanges from the `matched_tickers` DataFrame. This step ensures that each company's financial data is associated with its ticker symbol and the exchange it is listed on, providing a more comprehensive dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(matched_tickers[['CIK', 'Ticker', 'Exchange']], on='CIK', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e2a50",
   "metadata": {},
   "source": [
    "# Step 6: Analysis\n",
    "This code creates a new column in the DataFrame `df` called 'IA/Assets'. It calculates the percentage of Intangible Assets (IA) to Total Assets by dividing the values in the 'IA' column by the values in the 'Assets' column, converting them to floats, and multiplying the result by 100 to express it as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'IA/Assets' by dividing 'IA' by 'Assets'",
    "df['IA/Assets'] = df['IA'] / df['Assets'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afdf62",
   "metadata": {},
   "source": [
    "#### Substep 6.1 Seperate DataFrames\n",
    "This code creates two separate DataFrames, `nyse` and `nasdaq`, by filtering the main DataFrame `df` based on the value in the 'Exchange' column. The `nyse` DataFrame contains only rows where the 'Exchange' column is equal to 'NYSE', while the `nasdaq` DataFrame contains rows where the 'Exchange' column is equal to 'Nasdaq'. This separation allows for focused analysis on each exchange individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11015b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse = df[df['Exchange'] == 'NYSE']\n",
    "nasdaq = df[df['Exchange'] == 'Nasdaq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca61b",
   "metadata": {},
   "source": [
    "#### Substep 6.2: DataFrame by Year\n",
    "This code converts the 'Fiscal Year' column in both the `nyse` and `nasdaq` DataFrames to strings to ensure consistent data types for filtering. It then creates separate DataFrames for each exchange and fiscal year (2023 and 2024). This separation allows for focused analysis and comparison of Intangible Assets as a percentage of Total Assets (`IA/Assets`) across different exchanges and years, which will be visualized in subsequent steps.\n",
    "\n",
    "This step is essential because it ensures that the data is properly segmented by exchange and fiscal year, allowing for a more granular analysis. By creating separate DataFrames for each combination of exchange and year, we can calculate and compare metrics like `IA/Assets` more effectively. This segmentation also simplifies the process of generating visualizations and identifying trends or differences between the NYSE and Nasdaq exchanges over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change years to strings - Years in XBRL need to be converted to strings to properly create these new DataFrames\n",
    "nyse['Fiscal Year'] = nyse['Fiscal Year'].astype(str)\n",
    "nasdaq['Fiscal Year'] = nasdaq['Fiscal Year'].astype(str)\n",
    "# Make new DataFrames for each exhange and year\n",
    "nyse2023 = nyse[nyse['Fiscal Year'] == '2023']\n",
    "nyse2024 = nyse[nyse['Fiscal Year'] == '2024']\n",
    "nasdaq2024 = nasdaq[nasdaq['Fiscal Year'] == '2024']\n",
    "nasdaq2023 = nasdaq[nasdaq['Fiscal Year'] == '2023']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8011db6",
   "metadata": {},
   "source": [
    "#### Substep 6.3: Bar Plot\n",
    "This code generates a bar plot to visually compare the average percentage of Intangible Assets to Total Assets (IA/Assets) for companies listed on the NYSE and Nasdaq exchanges across two fiscal years (2023 and 2024). Each bar represents the average IA/Assets for a specific exchange and year combination, allowing for a clear comparison of trends and differences between the exchanges over time.\n",
    "\n",
    "This analysis is interesting because it highlights the differences in asset composition between companies listed on the NYSE and Nasdaq. Nasdaq, being tech-heavy, is expected to have a higher proportion of intangible assets compared to the more traditional companies on the NYSE. By comparing these percentages over two years, we can observe trends and assess whether these differences are consistent or evolving over time.\n",
    "\n",
    "The `plt.bar` line of code creates a bar plot with four bars, each representing the average percentage of Intangible Assets to Total Assets (IA/Assets) for a specific exchange and fiscal year combination. The x-axis labels ('2023 NYSE', '2024 NYSE', '2023 Nasdaq', '2024 Nasdaq') indicate the exchange and year, while the y-axis values are the mean IA/Assets percentages for the respective groups. The `color` parameter assigns distinct colors to each bar for better visual distinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290cee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(['2023 NYSE', '2024 NYSE', '2023 Nasdaq', '2024 Nasdaq'], \n",
    "        [nyse2023['IA/Assets'].mean(), nyse2024['IA/Assets'].mean(), nasdaq2023['IA/Assets'].mean(), nasdaq2024['IA/Assets'].mean()],\n",
    "        color=['blue', 'orange', 'green', 'red'])\n",
    "plt.title('Average IA/Assets by Exchange and Year')\n",
    "plt.xlabel('Exchange and Year')\n",
    "plt.ylabel('Average IA/Assets (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
   ["#### Interpreting the data\n",
    "\n",
   "The bar plot illustrates the average percentage of Intangible Assets to Total Assets (IA/Assets) for companies listed on the NYSE and Nasdaq across two fiscal years, 2023 and 2024. By comparing the heights of the bars, we can observe differences in asset composition between the exchanges, with Nasdaq companies generally expected to have higher IA/Assets due to their tech-heavy nature. \n",
    "\n",
   "In this analysis we can see that the New York Stock Exchange, on average, has a higher Intangible Assets to Total Assets ratio in 2023 and 2024 compared to the Nasdaq." ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b03167",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this exercise, we analyzed the financial differences between companies listed on the NYSE and Nasdaq by focusing on their intangible assets as a percentage of total assets. We started by obtaining and cleaning data from the SEC's JSON file and the XBRL API, matching tickers with their respective CIKs and exchanges. After querying the API for relevant financial data, we calculated the proportion of intangible assets (excluding goodwill) to total assets for each company. \n",
    "\n",
    "We then segmented the data by exchange (NYSE and Nasdaq) and fiscal year (2023 and 2024) to perform a comparative analysis. \n",
    "\n",
    "This analysis is significant because it provides insights into the structural differences between companies listed on these two major exchanges. Additionally, this exercise demonstrated the power of combining multiple data sources and Python libraries to perform advanced financial analysis efficiently.\n",
    "\n",
    "Now you have the tools to convert tickers into CIKs to create datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5380e",
   "metadata": {},
   "source": [
    "# Do on your own\n",
    "\n",
    "Using this exercise as a baseline find the XBRL concept tags to find Research & Development Expenses as a percentage of Revenue and compare the two Exchanges. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a01ba4",
   "metadata": {},
   "source": [
    "# Token Refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token if newrefresh != '' else refresh_token \n",
    "\n",
    "refresh_auth = {'client_id': 'a04fc50b-a62c-4e96-8578-6e71b3c9bc52', # change this to your client id\n",
    "                'client_secret' : 'dc6805e2-f03b-4f68-808d-89cfffcfc469', # change this to your client secret\n",
    "                'grant_type' : 'refresh_token',\n",
    "                'platform' : 'ipynb', \n",
    "                'refresh_token' : ''.join(token) }\n",
    "refreshres = requests.post(url, data=refresh_auth)\n",
    "refresh_json = refreshres.json()\n",
    "access_token = refresh_json['access_token']\n",
    "refresh_token = refresh_json['refresh_token']#print('access token: ' + access_token + 'refresh token: ' + refresh_token)\n",
    "print('Token Refreshed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
