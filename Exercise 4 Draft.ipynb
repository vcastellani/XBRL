{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Financial Statement Analysis #2\n",
    "In this exercise, we will conduct a financial statement analysis of the state commercial banking industry, classified under SIC code 6022. Our focus will be on identifying potential liquidity risks similar to those that contributed to the collapse of Silicon Valley Bank in 2022, particularly those stemming from Unrealized Losses on Available-for-Sale (AFS) securities.\n",
    "\n",
    "Banks differ in how they report Unrealized Gains and Losses (G/L) on AFS securities—some report these amounts before taxes, while others report them net of taxes. We will address this inconsistency in the dataset to ensure comparability across institutions. Once standardized, we will analyze each bank’s Unrealized G/L (both before and after tax) as a percentage of their total assets to assess potential security-related liquidity risks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Stata Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, json, requests, getpass, urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Obtain XBRL API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass(prompt = 'xX15892002$:')\n",
    "\n",
    "body_auth = {'username' : 'amm9890@psu.edu', \n",
    "            'client_id': 'cdbc60fc-a4b1-44f6-91bc-e7c8a9adf54a', \n",
    "            'client_secret' : 'a15b1993-7448-41db-ae43-ebeecb2cf26f', \n",
    "            'password' : ''.join(password), \n",
    "            'grant_type' : 'password', \n",
    "            'platform' : 'ipynb' }\n",
    "\n",
    "payload = urlencode(body_auth)\n",
    "url = 'https://api.xbrl.us/oauth2/token'\n",
    "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "\n",
    "res = requests.request(\"POST\", url, data = payload, headers = headers)\n",
    "auth_json = res.json()\n",
    "\n",
    "if 'error' in auth_json:\n",
    "    print (\"Access Denied\")\n",
    "else:\n",
    "    print (\"Access Granted.\")\n",
    "    \n",
    "access_token = auth_json['access_token']\n",
    "refresh_token = auth_json['refresh_token']\n",
    "newaccess = ''\n",
    "newrefresh = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: \n",
    "Define the XBRL elements we want to extract from the financial filings. These elements represent specific financial metrics or data points, such as unrealized gains/losses, income before tax, and total assets, which will be used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XBRL_Elements = ['OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodBeforeTax, OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodNetOfTax,IncomeLossFromContinuingOperationsBeforeIncomeTaxesExtraordinaryItemsNoncontrollingInterest,IncomeTaxExpenseBenefit,Assets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substep Step 3.2: \n",
    "For this step, we will be looking at 10-K filings in 2022. The analysis will focus on the SIC code \"6022,\" which includes all State Commercial Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filings = ['10-K']\n",
    "Years = ['2022']\n",
    "SIC = ['6022']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Substep 3.3: Run the Query\n",
    "The query will store the data in a DataFrame titled *df*. This step will look different from past exercises in the guide. Prior to converting API data pull into a DataFrame, the code will organize the concept tags (e.g., Assets) into their own column with their respective values. This will reduce the steps in cleaning the data and potential errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fields = ['entity.cik',\n",
    "          'entity.name.sort(ASC)',\n",
    "          'report.filing-date',\n",
    "          'period.fiscal-year',\n",
    "          'report.document-type',\n",
    "          'concept.local-name',\n",
    "          'fact.value',\n",
    "          'unit',\n",
    "          'report.sic-code']\n",
    "\n",
    "Parameters = {'concept.local-name': ','.join(XBRL_Elements),\n",
    "              'period.fiscal-year': ','.join(Years),\n",
    "              'unit': 'USD',\n",
    "              'report.document-type': ','.join(Filings),\n",
    "              'report.sic-code': ','.join(SIC),}  \n",
    "\n",
    "has_dimensions = 'FALSE'\n",
    "\n",
    "if has_dimensions == 'ALL':\n",
    "    dimension_options = ['TRUE', 'FALSE']\n",
    "else:\n",
    "    dimension_options = [has_dimensions]\n",
    "\n",
    "search_endpoint = 'https://api.xbrl.us/api/v1/fact/search'\n",
    "    \n",
    "all_res_list = []\n",
    "for dimensions_param in dimension_options:\n",
    "\n",
    "    print('Getting the data for: \"fact.has-dimensions\" = {}'.format(dimensions_param))\n",
    "    \n",
    "    done_retrieving_all_results = False\n",
    "    offset = 0\n",
    "\n",
    "    while not done_retrieving_all_results:\n",
    "\n",
    "        Parameters['fact.has-dimensions'] = dimensions_param\n",
    "        Parameters['fields'] = ','.join(Fields) + ',fact.offset({})'.format(offset) \n",
    "\n",
    "        res = requests.get(search_endpoint, params = Parameters, headers={'Authorization' : 'Bearer {}'.format(access_token)})\n",
    "        \n",
    "        res_json = res.json()\n",
    "        res_list = res_json['data']\n",
    "        all_res_list += res_list\n",
    "        \n",
    "        paging_dict = res_json['paging']\n",
    "\n",
    "        print('Number of Observations Obtained: ', paging_dict['count'])\n",
    "\n",
    "        if paging_dict['count'] >= 2000:\n",
    "            offset += paging_dict['count']\n",
    "        else:\n",
    "            done_retrieving_all_results = True\n",
    "\n",
    "\n",
    "\n",
    "restructured_data = []\n",
    "for item in all_res_list:\n",
    "    existing_entry = next(\n",
    "        (entry for entry in restructured_data if entry['entity.cik'] == item['entity.cik'] and entry['report.filing-date'] == item['report.filing-date']),\n",
    "        None\n",
    "    )\n",
    "   \n",
    "    if existing_entry:\n",
    "        existing_entry[item['concept.local-name']] = item['fact.value']\n",
    "    else:\n",
    "        new_entry = {\n",
    "            'entity.cik': item['entity.cik'],\n",
    "            'entity.name': item['entity.name'],\n",
    "            'report.filing-date': item['report.filing-date'],\n",
    "            'period.fiscal-year': item['period.fiscal-year'],\n",
    "            'report.document-type': item['report.document-type'],\n",
    "            'unit': item['unit'],\n",
    "            'report.sic-code': item['report.sic-code']\n",
    "        }\n",
    "        new_entry[item['concept.local-name']] = item['fact.value']\n",
    "        restructured_data.append(new_entry)\n",
    "    \n",
    "df = pd.DataFrame(restructured_data)\n",
    "print('Number of Observations: {}'.format(len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substep 3.4:\n",
    "In this step we will convert our DataFrame to banks. Whenever you are working with DataFrames and manipulating the code, make sure you are aware of the changes that are happening from step to step. Looking at the DataFrame will ensure the DataFrame is being properly manipulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = df\n",
    "banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Clean the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.1: Rename Columns\n",
    "In this step we will be changing the column names to be more presentable. There are different ways to do this using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks.rename(columns = {\n",
    "    'entity.cik': 'CIK',\n",
    "    'entity.name': 'Company',\n",
    "    'report.filing-date': 'Filing Date',\n",
    "    'period.fiscal-year': 'Year',\n",
    "    'report.document-type': 'Filing',\n",
    "    'IncomeLossFromContinuingOperationsBeforeIncomeTaxesExtraordinaryItemsNoncontrollingInterest': 'Income Before Tax',\n",
    "    'OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodBeforeTax': 'Unrealized Gain/Loss Before Tax',\n",
    "    'OtherComprehensiveIncomeUnrealizedHoldingGainLossOnSecuritiesArisingDuringPeriodNetOfTax': 'Unrealized Gain/Loss After Tax',\n",
    "    'Assets': 'Total Assets',\n",
    "    'fact.value': 'Value',\n",
    "    'unit': 'Unit',\n",
    "    'report.sic-code': 'SIC code'\n",
    "}, inplace=True)\n",
    "\n",
    "banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.2: Remove Duplicate Observations\n",
    "In this step, we are performing two operations on the `banks` DataFrame:\n",
    "\n",
    "1. **Sorting the DataFrame**: We first sort the rows of the `banks` DataFrame by the columns `CIK` and `Filing` in ascending order. This ensures that the data is organized in a consistent order, which is helpful for identifying duplicates.\n",
    "\n",
    "2. **Removing Duplicates**: After sorting, we remove duplicate rows based on the combination of the `CIK` and `Filing` columns. If multiple rows have the same values for these columns, only the first occurrence is kept, and the rest are dropped. This helps to ensure that each unique combination of `CIK` and `Filing` appears only once in the resulting DataFrame, `banks2`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks2 = banks.sort_values(by=['CIK', 'Filing'])\n",
    "banks2 = banks2.drop_duplicates(subset=['CIK', 'Filing'], keep='first')\n",
    "banks2 = banks2.reset_index(drop=True, inplace=True)"
    "banks2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.3: Remove NaN Variables\n",
    "In this step, we are cleaning the `banks2` DataFrame by removing rows that contain missing (`NaN`) values in the columns `'IncomeTaxExpenseBenefit'` and `'Income Before Tax'`. These columns are essential for subsequent calculations, such as determining the tax rate. By dropping rows with missing values in these columns, we ensure that the data is complete and compatible for performing accurate calculations in later steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks2 = banks2.dropna(subset=['IncomeTaxExpenseBenefit', 'Income Before Tax'])\n",
    "banks2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.4: Create Tax Rate Column\n",
    "\n",
    "In this step, we calculate the tax rate for each row in the `banks2` DataFrame. The tax rate is determined by dividing the `IncomeTaxExpenseBenefit` column by the `Income Before Tax` column. Subsequent steps will use this calculated tax rate to impute missing values for Unrealized Gain/Loss Before Tax and Unrealized Gain/Loss After Tax. The resulting tax rate is added as a new column, `tax rate,` to the `banks2` DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks2['tax rate'] = banks2['IncomeTaxExpenseBenefit'] / banks2['Income Before Tax']\n",
    "banks2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.4: Calculate NaN values for Columns of Unrealized G/L Before and After Tax\n",
    "In this step, we calculate the imputed values for Unrealized Gain/Loss Before Tax and Unrealized Gain/Loss After Tax using the tax rate. These calculations help fill in missing values for these columns in subsequent steps.\n",
    "\n",
    "1. **Imputed Unrealized Gain/Loss Before Tax**: This is calculated by multiplying the Unrealized Gain/Loss After Tax by `(1 + tax rate)`. This formula assumes that the Unrealized Gain/Loss After Tax already accounts for the tax effect, and we reverse this effect to estimate the value before tax.\n",
    "\n",
    "2. **Imputed Unrealized Gain/Loss After Tax**: This is calculated by multiplying the Unrealized Gain/Loss Before Tax by `(1 - tax rate)`. This formula applies the tax effect to the Unrealized Gain/Loss Before Tax to estimate the value after tax.\n",
    "\n",
    "These imputed values are stored in two new columns: `'imputed before tax'` and `'imputed after tax'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks2['imputed before tax'] = banks2['Unrealized Gain/Loss After Tax'] * (1 + banks2['tax rate'])\n",
    "banks2['imputed after tax'] = banks2['Unrealized Gain/Loss Before Tax'] * (1 - banks2['tax rate'])\n",
    "banks2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 4.5: Replacing NaN values with Imputed Versions\n",
    "In this step, we fill missing (`NaN`) values in the columns `'Unrealized Gain/Loss Before Tax'` and `'Unrealized Gain/Loss After Tax'` with their respective imputed values (`'imputed before tax'` and `'imputed after tax'`). After filling the missing values, the imputed columns are dropped from the DataFrame to clean up unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_calculated = banks2.copy()\n",
    "banks_calculated['Unrealized Gain/Loss Before Tax'].fillna(\n",
    "    banks_calculated['imputed before tax'], inplace=True\n",
    ")\n",
    "banks_calculated['Unrealized Gain/Loss After Tax'].fillna(\n",
    "    banks_calculated['imputed after tax'], inplace=True\n",
    ")\n",
    "\n",
    "banks_calculated = banks_calculated.drop(columns=['imputed before tax', 'imputed after tax'])\n",
    "banks_calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substep 4.6: Creating Variable of Interest\n",
    "In this step, we calculate two new columns, `Liquidity AT` and `Liquidity BT`, for the `banks_calculated` DataFrame. These columns represent the liquidity percentages based on Unrealized Gain/Loss After Tax and Unrealized Gain/Loss Before Tax, respectively.\n",
    "\n",
    "1. **Liquidity AT**: This is calculated by dividing the `Unrealized Gain/Loss After Tax` column by the `Total Assets` column and multiplying the result by 100. This gives the liquidity percentage after tax.\n",
    "\n",
    "2. **Liquidity BT**: This is calculated by dividing the `Unrealized Gain/Loss Before Tax` column by the `Total Assets` column and multiplying the result by 100. This gives the liquidity percentage before tax.\n",
    "\n",
    "These calculations provide insights into the proportion of unrealized gains or losses relative to the total assets of each bank, both before and after tax effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_calculated['Liquidity AT'] = banks_calculated['Unrealized Gain/Loss After Tax'] / banks_calculated['Total Assets'] * 100\n",
    "banks_calculated['Liquidity BT'] = banks_calculated['Unrealized Gain/Loss Before Tax'] / banks_calculated['Total Assets'] * 100\n",
    "banks_calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Analyzing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 5.1: Stastical Summary\n",
    "Here we will look at the stastical summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidity_stats = banks_calculated[['Liquidity AT', 'Liquidity BT']].describe()\n",
    "print(liquidity_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substep 5.2: Histogram\n",
    "Here, we are creating a histogram to show the distribution among the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_calculated['Liquidity AT'].dropna().hist(bins=20, edgecolor='black', figsize=(10, 6))\n",
    "plt.title('Histogram of Liquidity AT')\n",
    "plt.xlabel('Liquidity AT (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_calculated['Liquidity BT'].dropna().hist(bins=20, edgecolor='black', figsize=(10, 6))\n",
    "plt.title('Histogram of Liquidity BT')\n",
    "plt.xlabel('Liquidity BT (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This exercise highlights the importance of creativity when working with inconsistent financial data. Banks report unrealized gains and losses differently—some before tax, others after—which complicates direct comparisons. By creatively restructuring the API data and aligning mismatched fields, we were able to standardize the information and calculate meaningful ratios like unrealized losses as a percentage of total assets. This approach is crucial for uncovering hidden risks, such as those that contributed to the collapse of Silicon Valley Bank, and shows how flexible thinking leads to more accurate, insightful analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
